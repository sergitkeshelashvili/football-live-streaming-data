# âš½ Football Live Streaming Data Pipeline

A real-time football event streaming pipeline showcasing modern data engineering, stream processing, and Medallion (Lakehouse) architecture.

FastAPI â†’ Kafka (3 brokers) â†’ NiFi â†’ PostgreSQL (Master & Replica) â†’ Spark (Bronzeâ€“Silverâ€“Gold)
PySpark ETL orchestrated with Apache Airflow

# ğŸ“Š Architecture Overview

![Data Workflow Diagram](docs/data_workflow_diagram.png) 

FastAPI simulates live football events

Kafka streams events at high throughput

NiFi consumes Kafka and writes raw events to PostgreSQL

PostgreSQL stores event logs and analytics tables

Spark (PySpark) processes data into Bronze, Silver, and Gold layers

Airflow schedules and monitors the Spark ETL job

# ğŸ§± Medallion Architecture

Bronze â€“ Raw event capture from event_logs

Silver â€“ Cleaned and deduplicated events

Gold â€“ Aggregated team statistics (goals, fouls, shots)

ğŸ›  Tech Stack

FastAPI Â· Kafka Â· NiFi Â· PostgreSQL Â· Spark Â· Airflow Â· Python Â· SQL

# â± ETL & Orchestration

Raw events are first written to PostgreSQL event log tables

PySpark ETL transforms data across Bronze â†’ Silver â†’ Gold

Apache Airflow orchestrates and schedules the ETL pipeline

JDBC-based reads/writes ensure reliable batch processing

# ğŸ¯ Purpose

A portfolio-grade project demonstrating:

Real-time streaming pipelines

Scalable data ingestion

Medallion architecture implementation

Spark + Airflow production patterns

Sports analytics use cases
